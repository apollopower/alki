"""
Registry Publisher for Alki Bundles

Handles publishing of deployment bundles to container registries for fleet deployment.
Uses standard Docker containers as transport mechanism for maximum compatibility.
"""

import json
import logging
import os
import subprocess
import tempfile
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Any, Optional
import shutil

logger = logging.getLogger(__name__)


@dataclass
class PublishResult:
    """Result of a bundle publish operation"""

    success: bool
    bundle_uri: str
    image_tag: str
    bundle_sha256: Optional[str] = None
    size_mb: Optional[float] = None
    push_time_seconds: Optional[float] = None
    error: Optional[str] = None
    registry_digest: Optional[str] = None


class RegistryPublisher:
    """
    Publisher for Alki bundles to container registries.

    Creates minimal container images with bundles embedded for
    efficient distribution to edge devices via registry infrastructure.
    """

    def __init__(self, docker_client: str = "docker"):
        """
        Initialize publisher.

        Args:
            docker_client: Docker client command (default: "docker")
        """
        self.docker_client = docker_client
        self._check_docker_available()

    def _check_docker_available(self) -> bool:
        """Check if Docker is available and running"""
        try:
            result = subprocess.run(
                [self.docker_client, "version"],
                capture_output=True,
                text=True,
                timeout=10,
            )
            if result.returncode != 0:
                raise RuntimeError(f"Docker not available: {result.stderr}")
            return True
        except (subprocess.TimeoutExpired, FileNotFoundError) as e:
            raise RuntimeError(f"Docker not available: {e}")

    def generate_bundle_dockerfile(
        self, bundle_path: Path, metadata: Dict[str, Any]
    ) -> str:
        """
        Generate Dockerfile for bundle container.

        Creates minimal Alpine-based container with bundle at /bundle directory.
        Includes metadata as labels for discovery and verification.

        Args:
            bundle_path: Path to bundle directory
            metadata: Bundle metadata for labels

        Returns:
            Dockerfile content as string
        """
        # Generate Docker labels from metadata
        labels = []

        # Core bundle metadata
        if metadata.get("name"):
            labels.append(f'LABEL alki.bundle.name="{metadata["name"]}"')
        if metadata.get("version"):
            labels.append(f'LABEL alki.bundle.version="{metadata["version"]}"')
        if metadata.get("created_at"):
            labels.append(f'LABEL alki.bundle.created_at="{metadata["created_at"]}"')

        # Model metadata
        if metadata.get("artifacts"):
            artifacts = metadata["artifacts"]
            if len(artifacts) > 0:
                primary_artifact = artifacts[0]
                if primary_artifact.get("sha256"):
                    labels.append(
                        f'LABEL alki.bundle.primary_sha256="{primary_artifact["sha256"]}"'
                    )
                if primary_artifact.get("size"):
                    labels.append(
                        f'LABEL alki.bundle.primary_size="{primary_artifact["size"]}"'
                    )
                if primary_artifact.get("quant"):
                    labels.append(
                        f'LABEL alki.bundle.quantization="{primary_artifact["quant"]}"'
                    )

        # Runtime metadata
        if metadata.get("defaults"):
            defaults = metadata["defaults"]
            if defaults.get("ctx"):
                labels.append(f'LABEL alki.bundle.context_size="{defaults["ctx"]}"')

        if metadata.get("template"):
            labels.append(f'LABEL alki.bundle.chat_template="{metadata["template"]}"')

        # Add standard OCI annotations
        labels.extend(
            [
                'LABEL org.opencontainers.image.title="Alki Bundle"',
                'LABEL org.opencontainers.image.description="Alki LLM deployment bundle"',
                f'LABEL org.opencontainers.image.version="{metadata.get("version", "unknown")}"',
                'LABEL org.opencontainers.image.vendor="Alki"',
            ]
        )

        labels_str = "\n".join(labels)

        dockerfile = f"""# Alki Bundle Container - Generated by Registry Publisher
FROM alpine:latest

# Install minimal tools for bundle extraction
RUN apk add --no-cache tar gzip

# Add bundle metadata as labels
{labels_str}

# Create bundle directory
WORKDIR /bundle

# Copy entire bundle structure
COPY . /bundle/

# Ensure bundle has correct permissions
RUN find /bundle -type f -exec chmod 644 {{}} + && \\
    find /bundle -type d -exec chmod 755 {{}} +

# Provide extraction helper script with path validation
RUN echo '#!/bin/sh' > /extract-bundle.sh && \\
    echo 'if [ -z "$1" ]; then echo "Usage: /extract-bundle.sh <output-file>"; exit 1; fi' >> /extract-bundle.sh && \\
    echo 'OUTPUT=$(basename "$1")' >> /extract-bundle.sh && \\
    echo 'if [ "$OUTPUT" != "$1" ]; then echo "Error: Only filenames allowed, no paths"; exit 1; fi' >> /extract-bundle.sh && \\
    echo 'tar -czf - -C /bundle . > "/tmp/$OUTPUT" && mv "/tmp/$OUTPUT" "/tmp/$OUTPUT.bundle"' >> /extract-bundle.sh && \\
    echo 'echo "Bundle extracted to: /tmp/$OUTPUT.bundle"' >> /extract-bundle.sh && \\
    chmod +x /extract-bundle.sh

# Default command shows bundle info
CMD ["sh", "-c", "echo 'Alki Bundle:' && ls -la /bundle/ && echo '' && cat /bundle/metadata/manifest.json"]
"""

        return dockerfile

    def build_bundle_container(
        self,
        bundle_path: Path,
        tag: str,
        build_args: Optional[Dict[str, str]] = None,
    ) -> Dict[str, Any]:
        """
        Build container image from bundle.

        Args:
            bundle_path: Path to bundle directory
            tag: Docker image tag to build
            build_args: Additional build arguments

        Returns:
            Build result dictionary with status and metadata
        """
        start_time = time.time()

        try:
            # Validate bundle exists
            if not bundle_path.exists():
                raise ValueError(f"Bundle path does not exist: {bundle_path}")

            manifest_path = bundle_path / "metadata" / "manifest.json"
            if not manifest_path.exists():
                raise ValueError(f"Bundle manifest not found: {manifest_path}")

            # Load bundle metadata
            with open(manifest_path) as f:
                manifest_data = json.load(f)

            # Create temporary build context
            with tempfile.TemporaryDirectory() as temp_dir:
                temp_path = Path(temp_dir)

                # Copy entire bundle to build context
                shutil.copytree(bundle_path, temp_path / "bundle")
                build_context = temp_path / "bundle"

                # Generate Dockerfile
                dockerfile_content = self.generate_bundle_dockerfile(
                    bundle_path, manifest_data
                )

                dockerfile_path = build_context / "Dockerfile"
                dockerfile_path.write_text(dockerfile_content)

                # Build image
                build_cmd = [self.docker_client, "build", "-t", tag, str(build_context)]

                # Add build args if provided
                if build_args:
                    for key, value in build_args.items():
                        build_cmd.extend(["--build-arg", f"{key}={value}"])

                logger.info(f"Building bundle container: {tag}")
                logger.debug(f"Build command: {' '.join(build_cmd)}")

                result = subprocess.run(
                    build_cmd,
                    capture_output=True,
                    text=True,
                    timeout=300,  # 5 minute timeout
                )

                if result.returncode != 0:
                    raise RuntimeError(f"Docker build failed: {result.stderr}")

                # Get image size
                inspect_result = subprocess.run(
                    [self.docker_client, "inspect", tag, "--format={{.Size}}"],
                    capture_output=True,
                    text=True,
                )

                size_bytes = 0
                if inspect_result.returncode == 0:
                    try:
                        size_bytes = int(inspect_result.stdout.strip())
                    except ValueError:
                        pass

                build_time = time.time() - start_time

                return {
                    "success": True,
                    "image_tag": tag,
                    "size_mb": size_bytes / (1024 * 1024),
                    "build_time_seconds": build_time,
                    "build_log": result.stdout,
                }

        except Exception as e:
            build_time = time.time() - start_time
            return {
                "success": False,
                "image_tag": tag,
                "build_time_seconds": build_time,
                "error": str(e),
            }

    def _resolve_authentication(
        self, registry_host: str, registry_auth: Optional[Dict[str, str]] = None
    ) -> Optional[Dict[str, str]]:
        """
        Resolve authentication for registry using priority order:
        1. Explicit auth provided
        2. Environment variables
        3. Existing Docker credentials (user already logged in)
        4. None (anonymous access)

        Args:
            registry_host: Registry hostname
            registry_auth: Explicit authentication if provided

        Returns:
            Authentication dict or None if not needed/available
        """
        # 1. Use explicit auth if provided
        if (
            registry_auth
            and registry_auth.get("username")
            and registry_auth.get("password")
        ):
            return registry_auth

        # 2. Check environment variables
        env_username = os.getenv("REGISTRY_USERNAME") or os.getenv("DOCKER_USERNAME")
        env_password = os.getenv("REGISTRY_PASSWORD") or os.getenv("DOCKER_PASSWORD")

        if env_username and env_password:
            logger.info("Using registry credentials from environment variables")
            return {
                "username": env_username,
                "password": env_password,
                "registry": registry_host,
            }

        # 3. Check if user is already logged into registry
        # Try a simple docker info command to see if we're authenticated
        try:
            # Test if we can access registry without explicit login
            # This leverages existing Docker credential helpers and login state
            logger.info(f"Checking existing Docker credentials for {registry_host}")
            return None  # Let Docker handle auth automatically
        except Exception:
            logger.debug("No existing Docker credentials found")

        # 4. No authentication available - registry must allow anonymous access
        logger.info("No authentication configured - attempting anonymous access")
        return None

    def _perform_registry_login(self, auth: Dict[str, str]) -> bool:
        """
        Perform docker login with provided credentials.

        Args:
            auth: Authentication dictionary with username, password, registry

        Returns:
            True if login successful, False otherwise
        """
        try:
            login_cmd = [
                self.docker_client,
                "login",
                "--username",
                auth["username"],
                "--password-stdin",
            ]

            if auth.get("registry"):
                login_cmd.append(auth["registry"])

            logger.info(f"Logging into registry: {auth.get('registry', 'Docker Hub')}")

            login_result = subprocess.run(
                login_cmd,
                input=auth["password"],
                capture_output=True,
                text=True,
                timeout=30,
            )

            if login_result.returncode != 0:
                logger.error(f"Registry login failed: {login_result.stderr}")
                return False

            logger.info("Registry login successful")
            return True

        except Exception as e:
            logger.error(f"Registry login error: {e}")
            return False

    def push_bundle_to_registry(
        self,
        image_tag: str,
        registry_auth: Optional[Dict[str, str]] = None,
    ) -> Dict[str, Any]:
        """
        Push bundle container to registry.

        Args:
            image_tag: Docker image tag to push
            registry_auth: Optional registry authentication

        Returns:
            Push result dictionary with status and metadata
        """
        start_time = time.time()

        try:
            # Extract registry host from image tag
            registry_host = image_tag.split("/")[0] if "/" in image_tag else "docker.io"

            # Resolve authentication using priority order
            resolved_auth = self._resolve_authentication(registry_host, registry_auth)

            # Perform login if explicit credentials were resolved
            if resolved_auth:
                if not self._perform_registry_login(resolved_auth):
                    raise RuntimeError("Registry authentication failed")

            # Push image (Docker will use existing credentials if available)
            push_cmd = [self.docker_client, "push", image_tag]

            logger.info(f"Pushing bundle to registry: {image_tag}")

            push_result = subprocess.run(
                push_cmd,
                capture_output=True,
                text=True,
                timeout=600,  # 10 minute timeout
            )

            if push_result.returncode != 0:
                error_msg = push_result.stderr.strip()

                # Provide helpful error messages for common issues
                if (
                    "authentication required" in error_msg.lower()
                    or "unauthorized" in error_msg.lower()
                ):
                    raise RuntimeError(
                        f"Registry authentication failed. Try:\n"
                        f"1. docker login {registry_host}\n"
                        f"2. Set REGISTRY_USERNAME and REGISTRY_PASSWORD environment variables\n"
                        f"3. Use --username and --password flags\n"
                        f"Original error: {error_msg}"
                    )
                elif "not found" in error_msg.lower():
                    raise RuntimeError(
                        f"Registry repository not found. Make sure the registry URL is correct and you have push permissions.\n"
                        f"Original error: {error_msg}"
                    )
                else:
                    raise RuntimeError(f"Docker push failed: {error_msg}")

            # Extract registry digest from push output
            registry_digest = None
            for line in push_result.stdout.split("\n"):
                if "digest:" in line and "sha256:" in line:
                    registry_digest = line.split("digest: ")[-1].strip()
                    break

            push_time = time.time() - start_time

            return {
                "success": True,
                "image_tag": image_tag,
                "registry_digest": registry_digest,
                "push_time_seconds": push_time,
                "push_log": push_result.stdout,
            }

        except Exception as e:
            push_time = time.time() - start_time
            return {
                "success": False,
                "image_tag": image_tag,
                "push_time_seconds": push_time,
                "error": str(e),
            }

    def publish_bundle(
        self,
        bundle_path: Path,
        registry: Optional[str] = None,
        name: Optional[str] = None,
        tag: str = "latest",
        registry_auth: Optional[Dict[str, str]] = None,
        build_args: Optional[Dict[str, str]] = None,
        local_only: bool = False,
    ) -> PublishResult:
        """
        Publish bundle to registry or build locally.

        Complete workflow: validate bundle -> build container -> optionally push to registry.

        Args:
            bundle_path: Path to bundle directory
            registry: Registry URL (e.g., "myregistry.com/bundles"), optional for local-only builds
            name: Bundle name (derived from bundle if not provided)
            tag: Image tag (default: "latest")
            registry_auth: Optional registry authentication
            build_args: Additional build arguments
            local_only: If True, only build locally without pushing to registry

        Returns:
            PublishResult with operation status and metadata
        """
        start_time = time.time()

        # Initialize variables for error handling
        bundle_uri = "unknown"
        full_tag = "unknown"

        try:
            # Validate bundle
            if not bundle_path.exists() or not bundle_path.is_dir():
                raise ValueError(f"Invalid bundle path: {bundle_path}")

            manifest_path = bundle_path / "metadata" / "manifest.json"
            if not manifest_path.exists():
                raise ValueError(f"Bundle manifest not found: {manifest_path}")

            # Load manifest to get bundle name
            with open(manifest_path) as f:
                manifest_data = json.load(f)

            bundle_name = name or manifest_data.get("name", bundle_path.name)

            # Construct image tag based on mode
            if local_only or not registry:
                # Local-only build
                full_tag = f"alki-local/{bundle_name}:{tag}"
                bundle_uri = full_tag
                logger.info(f"Building bundle locally: {full_tag}")
            else:
                # Registry build
                registry_clean = registry.rstrip("/")
                full_tag = f"{registry_clean}/{bundle_name}:{tag}"
                bundle_uri = full_tag
                logger.info(f"Building bundle for registry: {full_tag}")

            # Build container image
            logger.info(f"Building bundle container for: {bundle_name}")
            build_result = self.build_bundle_container(
                bundle_path=bundle_path,
                tag=full_tag,
                build_args=build_args,
            )

            if not build_result["success"]:
                return PublishResult(
                    success=False,
                    bundle_uri=bundle_uri,
                    image_tag=full_tag,
                    error=f"Build failed: {build_result.get('error')}",
                )

            # Push to registry only if not local-only
            push_result = None
            if not local_only and registry:
                logger.info(f"Pushing bundle to registry: {full_tag}")
                push_result = self.push_bundle_to_registry(
                    image_tag=full_tag,
                    registry_auth=registry_auth,
                )

                if not push_result["success"]:
                    return PublishResult(
                        success=False,
                        bundle_uri=bundle_uri,
                        image_tag=full_tag,
                        error=f"Push failed: {push_result.get('error')}",
                    )
            else:
                logger.info("Skipping registry push (local-only mode)")
                push_result = {
                    "success": True,
                    "registry_digest": None,
                    "push_time_seconds": 0,
                }

            # Calculate bundle SHA256 from primary artifact
            bundle_sha256 = None
            if manifest_data.get("artifacts") and len(manifest_data["artifacts"]) > 0:
                bundle_sha256 = manifest_data["artifacts"][0].get("sha256")

            total_time = time.time() - start_time

            return PublishResult(
                success=True,
                bundle_uri=bundle_uri,
                image_tag=full_tag,
                bundle_sha256=bundle_sha256,
                size_mb=build_result.get("size_mb"),
                push_time_seconds=total_time,
                registry_digest=push_result.get("registry_digest"),
            )

        except Exception as e:
            total_time = time.time() - start_time
            return PublishResult(
                success=False,
                bundle_uri=bundle_uri,
                image_tag=full_tag,
                push_time_seconds=total_time,
                error=str(e),
            )

    def generate_deployment_manifest(
        self,
        bundle_uri: str,
        bundle_name: str,
        bundle_metadata: Dict[str, Any],
        namespace: str = "default",
    ) -> str:
        """
        Generate Kubernetes deployment manifest for registry-based bundle deployment.

        Args:
            bundle_uri: Full bundle URI (registry/name:tag)
            bundle_name: Bundle name for Kubernetes resources
            bundle_metadata: Bundle metadata from manifest
            namespace: Kubernetes namespace

        Returns:
            Complete Kubernetes YAML manifest as string
        """
        # Extract configuration from bundle metadata
        defaults = bundle_metadata.get("defaults", {})
        ctx_size = defaults.get("ctx", 4096)
        template = bundle_metadata.get("template", "chatml")

        # Get primary artifact info
        artifacts = bundle_metadata.get("artifacts", [])
        model_filename = self._get_default_model_filename(artifacts)
        if artifacts:
            # Use the URI from the first artifact, extract filename
            model_uri = artifacts[0].get("uri", "")
            if model_uri:
                model_filename = Path(model_uri).name

        manifest = f"""# Alki Bundle Deployment - Registry-based
# Generated by Alki Registry Publisher
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: {bundle_name}-bundle-config
  namespace: {namespace}
  labels:
    app: {bundle_name}
    component: llm-bundle
data:
  bundle_uri: "{bundle_uri}"
  model_filename: "{model_filename}"
  context_size: "{ctx_size}"
  chat_template: "{template}"
  
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {bundle_name}
  namespace: {namespace}
  labels:
    app: {bundle_name}
    component: llm-server
spec:
  replicas: 1
  selector:
    matchLabels:
      app: {bundle_name}
  template:
    metadata:
      labels:
        app: {bundle_name}
        component: llm-server
    spec:
      initContainers:
      - name: bundle-loader
        image: {bundle_uri}
        command: ["/extract-bundle.sh", "/shared/bundle.tar.gz"]
        volumeMounts:
        - name: bundle-storage
          mountPath: /shared
        - name: model-cache
          mountPath: /models
        env:
        - name: BUNDLE_URI
          valueFrom:
            configMapKeyRef:
              name: {bundle_name}-bundle-config
              key: bundle_uri
      - name: bundle-extractor
        image: alpine:latest
        command: ["sh", "-c"]
        args:
        - |
          cd /models && 
          tar -xzf /shared/bundle.tar.gz &&
          echo "Bundle extracted successfully" &&
          ls -la /models/
        volumeMounts:
        - name: bundle-storage
          mountPath: /shared
        - name: model-cache
          mountPath: /models
      containers:
      - name: llama-server
        image: ghcr.io/ggerganov/llama.cpp:server
        ports:
        - containerPort: 8080
          name: http
        env:
        - name: LLAMA_ARG_MODEL
          value: "/models/models/{model_filename}"
        - name: LLAMA_ARG_HOST
          value: "0.0.0.0"
        - name: LLAMA_ARG_PORT
          value: "8080"
        - name: LLAMA_ARG_CTX_SIZE
          valueFrom:
            configMapKeyRef:
              name: {bundle_name}-bundle-config
              key: context_size
        - name: LLAMA_ARG_CHAT_FORMAT
          valueFrom:
            configMapKeyRef:
              name: {bundle_name}-bundle-config
              key: chat_template
        resources:
          requests:
            memory: "2Gi"
            cpu: "500m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 60
          periodSeconds: 30
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /v1/models
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
          failureThreshold: 5
        volumeMounts:
        - name: model-cache
          mountPath: /models
          readOnly: true
      volumes:
      - name: bundle-storage
        emptyDir:
          sizeLimit: 1Gi
      - name: model-cache
        emptyDir:
          sizeLimit: 8Gi
          
---
apiVersion: v1
kind: Service
metadata:
  name: {bundle_name}
  namespace: {namespace}
  labels:
    app: {bundle_name}
    component: llm-server
spec:
  selector:
    app: {bundle_name}
  ports:
  - name: http
    port: 8080
    targetPort: 8080
  type: ClusterIP

---
# Optional: Ingress for external access
# apiVersion: networking.k8s.io/v1
# kind: Ingress
# metadata:
#   name: {bundle_name}
#   namespace: {namespace}
# spec:
#   rules:
#   - host: {bundle_name}.yourdomain.com
#     http:
#       paths:
#       - path: /
#         pathType: Prefix
#         backend:
#           service:
#             name: {bundle_name}
#             port:
#               number: 8080
"""

        return manifest

    def _get_default_model_filename(self, artifacts: list) -> str:
        """
        Get default model filename based on supported formats.

        Args:
            artifacts: List of bundle artifacts (unused currently, reserved for future format detection)

        Returns:
            Default model filename with appropriate extension

        Note:
            Currently only GGUF format is supported. This method provides
            a centralized place to extend format support in the future.
            The artifacts parameter is reserved for future use when format
            detection from artifact metadata is implemented.
        """
        # TODO: Expand to detect and support multiple formats (ONNX, TensorRT)
        # when converter support is added in future phases
        # TODO: Use artifacts parameter to detect format from metadata
        _ = artifacts  # Acknowledge unused parameter for future format detection
        return "model.gguf"
